{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/10 20:23:36 WARN Utils: Your hostname, user-ubuntu-pc resolves to a loopback address: 127.0.1.1; using 192.168.1.7 instead (on interface wlo1)\n",
      "22/12/10 20:23:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/10 20:23:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Создаём спарк контекст\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master('local[32]')\\\n",
    "        .appName('HW5')\\\n",
    "        .config('spark.ui.port', '4050')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv('jigsaw-toxic-comment-classification-challenge/train.csv', sep=',', quote='\\\"', escape='\\\"', multiLine=True, header=True, inferSchema=True)\n",
    "test = spark.read.csv('jigsaw-toxic-comment-classification-challenge/test.csv', sep=',', quote='\\\"', escape='\\\"', multiLine=True, header=True, inferSchema=True)\n",
    "test_labels = spark.read.csv('jigsaw-toxic-comment-classification-challenge/test_labels.csv', sep=',', quote='\\\"', escape='\\\"', multiLine=True, header=True, inferSchema=True)\n",
    "test = test.join(test_labels, 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/10 20:27:25 WARN CacheManager: Asked to cache already cached data.\n",
      "22/12/10 20:27:25 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 232:>                                                        (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.classification import FMClassifier\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MultilabelClassificationEvaluator\n",
    "\n",
    "\n",
    "target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate',]\n",
    "\n",
    "# lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
    "# nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "# fm = FMClassifier(labelCol=\"indexedLabel\", featuresCol=\"scaledFeatures\", stepSize=0.001)\n",
    "# lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "# models = [('lsvc', lsvc), ('nb', nb), ('fm', fm), ('lr', lr),]\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"words\")\n",
    "\n",
    "train_tokenized = tokenizer.transform(train).cache()\n",
    "test_tokenized = tokenizer.transform(test).cache()\n",
    "\n",
    "nums_scores = []\n",
    "for numFeatures in range(10, 200, 10):\n",
    "    scores = []\n",
    "\n",
    "    hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"tf\", numFeatures=numFeatures)\n",
    "    idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "    tf_idf_pipe = Pipeline(stages=[hashingTF, idf])\n",
    "    tf_idf_pipe = tf_idf_pipe.fit(train_tokenized)\n",
    "    train_tfidf = tf_idf_pipe.transform(train_tokenized)\n",
    "    test_tfidf = tf_idf_pipe.transform(test_tokenized)\n",
    "\n",
    "    model_stages = []\n",
    "    for target_name in target_cols:\n",
    "        model_stages.append(LogisticRegression(featuresCol=idf.getOutputCol(), labelCol=target_name, probabilityCol=f'{target_name}__probabilityCol', rawPredictionCol=f'{target_name}__rawPredictionCol',  predictionCol=f'{target_name}__predictionCol', maxIter=10, regParam=0.3, elasticNetParam=0.8))\n",
    "\n",
    "    model_pipe = Pipeline(stages=model_stages)\n",
    "    models_transformer = model_pipe.fit(train_tfidf)\n",
    "    results = models_transformer.transform(test_tfidf).select(*target_cols, *[f'{x}__probabilityCol' for x in target_cols]).cache()\n",
    "\n",
    "    for target_name in target_cols:\n",
    "\n",
    "        metrics = BinaryClassificationEvaluator(labelCol=target_name, rawPredictionCol=f'{target_name}__probabilityCol')\n",
    "        scores.append(metrics.evaluate(results))\n",
    "\n",
    "    results.unpersist()\n",
    "    nums_scores.append((numFeatures, sum(scores) / len(target_cols)))\n",
    "train_tokenized.unpersist()\n",
    "test_tokenized.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
